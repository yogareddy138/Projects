{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import torch\r\n",
    "from matplotlib.pyplot import figure\r\n",
    "import numpy as np\r\n",
    "from torch import  nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def activation(x):\r\n",
    "    return 1/(1+torch.exp(-x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from torchvision import datasets, transforms\r\n",
    "\r\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\r\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform = transform)\r\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "dataiter = iter(trainloader)\r\n",
    "images, labels = dataiter.next()\r\n",
    "print(images.shape)\r\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "inputs = images.view(images.shape[0], -1)\r\n",
    "\r\n",
    "w1 = torch.randn(784, 256)\r\n",
    "b1 = torch.randn(256)\r\n",
    "\r\n",
    "w2 = torch.randn(256, 10)\r\n",
    "b2 = torch.randn(10)\r\n",
    "\r\n",
    "h = activation(torch.mm(inputs, w1) + b1)\r\n",
    "\r\n",
    "out = torch.mm(h, w2) + b2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def softmax(x):\r\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim = 1).view(-1, 1)\r\n",
    "\r\n",
    "probabilities = softmax(out)\r\n",
    "\r\n",
    "print(probabilities.shape)\r\n",
    "print(probabilities.sum(dim = 1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "class Network(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.hidden = nn.Linear(784, 256)\r\n",
    "        self.output = nn.Linear(256, 10)\r\n",
    "\r\n",
    "        self.sigmoid = nn.Sigmoid()\r\n",
    "        self.softmax = nn.Softmax(dim = 1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.hidden(x)\r\n",
    "        x = self.sigmoid(x)\r\n",
    "        x = self.output(x)\r\n",
    "        x = self.softmax(x)\r\n",
    "\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "model = Network()\r\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "class Network(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.hidden = nn.Linear(784, 256)\r\n",
    "        self.output = nn.Linear(256, 10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = F.sigmoid(self.hidden(x))\r\n",
    "        x = F.softmax(self.output(x), dim = 1)\r\n",
    "\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10))\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "images, labels = next(iter(trainloader))\r\n",
    "images = images.view(images.shape[0], -1)\r\n",
    "logits = model(images)\r\n",
    "loss = criterion(logits, labels)\r\n",
    "\r\n",
    "print(loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2.2841, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), \r\n",
    "                      nn.Linear(128, 64), nn.ReLU(), \r\n",
    "                      nn.Linear(64, 10), nn.LogSoftmax(dim = 1))\r\n",
    "criterion = nn.NLLLoss()\r\n",
    "images, labels = next(iter(trainloader))\r\n",
    "images = images.view(images.shape[0], -1)\r\n",
    "logps = model(images)\r\n",
    "loss = criterion(logps, labels)\r\n",
    "\r\n",
    "print(loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2.2961, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.5973,  1.3909],\n",
      "        [-1.8782, -0.5111]], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "y = x**2\r\n",
    "print(y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.3567, 1.9346],\n",
      "        [3.5278, 0.2612]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "print(y.grad_fn)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<PowBackward0 object at 0x000001927F03C430>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "z = y.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "print(x.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "z.backward()\r\n",
    "print(x.grad)\r\n",
    "print(x/2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.2986,  0.6954],\n",
      "        [-0.9391, -0.2555]])\n",
      "tensor([[ 0.2986,  0.6954],\n",
      "        [-0.9391, -0.2555]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), \r\n",
    "                      nn.Linear(128, 64), nn.ReLU(), \r\n",
    "                      nn.Linear(64, 10), nn.LogSoftmax(dim = 1))\r\n",
    "criterion = nn.NLLLoss()\r\n",
    "images, labels = next(iter(trainloader))\r\n",
    "images = images.view(images.shape[0], -1)\r\n",
    "logps = model(images)\r\n",
    "loss = criterion(logps, labels)\r\n",
    "\r\n",
    "print(loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2.2988, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "print(\"Before Backward pass : \\n\", model[0].weight.grad)\r\n",
    "loss.backward()\r\n",
    "print(\"After Backward pass : \\n\",model[0].weight.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before Backward pass : \n",
      " None\n",
      "After Backward pass : \n",
      " tensor([[ 0.0036,  0.0036,  0.0036,  ...,  0.0036,  0.0036,  0.0036],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [-0.0022, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0022],\n",
      "        ...,\n",
      "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "from torch import optim\r\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "print('Inital weights - ', model[0].weight)\r\n",
    "\r\n",
    "images, labels = next(iter(trainloader))\r\n",
    "images.resize_(64, 784)\r\n",
    "\r\n",
    "optimizer.zero_grad()\r\n",
    "\r\n",
    "output = model.forward(images)\r\n",
    "loss = criterion(output, labels)\r\n",
    "loss.backward()\r\n",
    "print('Gradient -', model[0].weight.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inital weights -  Parameter containing:\n",
      "tensor([[ 1.9387e-02,  1.0676e-02,  5.9656e-03,  ..., -1.5762e-02,\n",
      "          6.6692e-03,  2.2570e-02],\n",
      "        [ 3.3890e-02,  5.0750e-03,  1.0938e-03,  ...,  2.7988e-02,\n",
      "          2.7544e-02,  3.4650e-02],\n",
      "        [-2.5923e-02, -2.8438e-02, -2.9675e-02,  ..., -1.7569e-02,\n",
      "         -6.7470e-03, -3.5486e-02],\n",
      "        ...,\n",
      "        [-1.0701e-02,  2.3796e-02, -1.0535e-02,  ..., -2.5587e-02,\n",
      "         -7.8063e-03, -2.8431e-05],\n",
      "        [-1.4640e-02, -2.4052e-02,  1.9437e-02,  ..., -2.2568e-02,\n",
      "          3.8320e-03,  2.2114e-02],\n",
      "        [ 1.3573e-02,  1.7200e-03,  3.2379e-02,  ...,  1.6092e-02,\n",
      "          2.1467e-02, -1.0497e-03]], requires_grad=True)\n",
      "Gradient - tensor([[-1.9258e-04, -1.9258e-04, -1.9258e-04,  ..., -1.9258e-04,\n",
      "         -1.9258e-04, -1.9258e-04],\n",
      "        [ 4.2689e-05,  4.2689e-05,  4.2689e-05,  ...,  4.2689e-05,\n",
      "          4.2689e-05,  4.2689e-05],\n",
      "        [-1.2110e-03, -1.2110e-03, -1.2110e-03,  ..., -1.2110e-03,\n",
      "         -1.2110e-03, -1.2110e-03],\n",
      "        ...,\n",
      "        [-4.7586e-03, -4.7586e-03, -4.7586e-03,  ..., -4.7586e-03,\n",
      "         -4.7586e-03, -4.7586e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 8.1380e-04,  8.1380e-04,  8.1380e-04,  ...,  8.1380e-04,\n",
      "          8.1380e-04,  8.1380e-04]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "optimizer.step()\r\n",
    "print('Updated weights -', model[0].weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated weights - Parameter containing:\n",
      "tensor([[ 1.9389e-02,  1.0678e-02,  5.9675e-03,  ..., -1.5760e-02,\n",
      "          6.6711e-03,  2.2572e-02],\n",
      "        [ 3.3890e-02,  5.0745e-03,  1.0934e-03,  ...,  2.7988e-02,\n",
      "          2.7543e-02,  3.4650e-02],\n",
      "        [-2.5911e-02, -2.8426e-02, -2.9663e-02,  ..., -1.7557e-02,\n",
      "         -6.7348e-03, -3.5474e-02],\n",
      "        ...,\n",
      "        [-1.0653e-02,  2.3844e-02, -1.0488e-02,  ..., -2.5539e-02,\n",
      "         -7.7587e-03,  1.9155e-05],\n",
      "        [-1.4640e-02, -2.4052e-02,  1.9437e-02,  ..., -2.2568e-02,\n",
      "          3.8320e-03,  2.2114e-02],\n",
      "        [ 1.3565e-02,  1.7119e-03,  3.2371e-02,  ...,  1.6084e-02,\n",
      "          2.1459e-02, -1.0579e-03]], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(),\r\n",
    "                      nn.Linear(128, 64), nn.ReLU(), \r\n",
    "                      nn.Linear(64, 10), nn.LogSoftmax(dim=1))\r\n",
    "\r\n",
    "criterion = nn.NLLLoss()\r\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003)\r\n",
    "\r\n",
    "epochs = 5\r\n",
    "\r\n",
    "for e in range(epochs):\r\n",
    "    running_loss = 0\r\n",
    "    for images, labels in trainloader:\r\n",
    "        images = images.view(images.shape[0], -1)\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        output = model.forward(images)\r\n",
    "        loss = criterion(output, labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        running_loss += loss.item()\r\n",
    "        \r\n",
    "    else:\r\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss: 1.8825670020666712\n",
      "Training loss: 0.8393916977938812\n",
      "Training loss: 0.5305155003979516\n",
      "Training loss: 0.431023176370272\n",
      "Training loss: 0.3852083096975711\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "%matplotlib inline\r\n",
    "import helper\r\n",
    "\r\n",
    "images, labels = next(iter(trainloader))\r\n",
    "img = images[0].view(1, 784)\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    logits = model.forward(img)\r\n",
    "\r\n",
    "ps = F.softmax(logits, dim=1)\r\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "3f6f9090607da7e5470f97ece8d94086f82b718ca6c452ac1c0276bbd1aa9e85"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}